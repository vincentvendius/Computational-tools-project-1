{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Customer Database\n",
    "**This is the first of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Your team has been hired by the company X as data scientists. X makes gadgets for a wide range of industrial and commercial clients.\n",
    "\n",
    "As in-house data scientists, your teams first task, as per request from your new boss, is to optimize business operations. You have decided that a good first step would be to analyze the companys historical sales data to gain a better understanding of where profit is coming from. It may also reveal some low hanging fruit in terms of business opportunities.\n",
    "\n",
    "To get started, you have called the IT department to get access to the customer and sales transactions database. To your horror you've been told that such a database doens't exist, and the only record of sales transactions is kept by John from finance in an Excel spreadsheet. So you've emailed John asking for a CSV dump of the spreadsheet...\n",
    "\n",
    "In this project you need to clean the data you got from John, enrich it with further data, prepare a database for the data, and do some data analysis. The project is comprised of five parts. They are intended to be solved in the order they appear, but it is highly recommended that you read through all of them and devise an overall strategy before you start implementing anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning the data\n",
    "John has emailed you the following link to the CSV dump you requested.\n",
    "\n",
    "- [transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)\n",
    "\n",
    "It seems as though he has been a bit sloppy when keeping the records. \n",
    "\n",
    "In this part you should:\n",
    "- Explain what the data is\n",
    "- Clean it to prepare it for inserting into a database and doing data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the csv file given to us by John from finances, a large table can be found. \n",
    "\n",
    "Each row represents a transaction from a sale of gadgets to a company. \n",
    "\n",
    "The file is loaded to get more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company country          city    price  \\\n",
       "0  54868-5165  Chatterbridge   Spain     Barcelona  784.79€   \n",
       "1  60505-2867           Lajo  Greece  Thessaloniki  187.99€   \n",
       "2   24385-268      Flipstorm  Greece        Athens  221.73€   \n",
       "\n",
       "                  date  \n",
       "0  2016-01-02 00:01:05  \n",
       "1  2016-01-02 00:05:26  \n",
       "2  2016-01-02 00:18:30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file\n",
    "df = pd.read_csv('transactions.csv', encoding='utf-8-sig')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20568"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_rows = len(df)\n",
    "start_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table consists of 20568 data rows and there are 6 columns of information for each transaction. \n",
    "\n",
    "The first column, part, is not unique nor does it give information important in regards to doing this exercise. Therefore, it is removed from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company country          city    price                 date\n",
       "0  Chatterbridge   Spain     Barcelona  784.79€  2016-01-02 00:01:05\n",
       "1           Lajo  Greece  Thessaloniki  187.99€  2016-01-02 00:05:26\n",
       "2      Flipstorm  Greece        Athens  221.73€  2016-01-02 00:18:30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['part'], inplace=True, axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain a better knowledge of the type of data, the first order of business is to figure out what type of data we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company    object\n",
       "country    object\n",
       "city       object\n",
       "price      object\n",
       "date       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output tells us that the data in all the columns is of `object` type - also known as `str` type. However, from the table it is clear that the data in the price and date columns should not be an `object` but rather a `float` and `datetime`, respectively. \n",
    "\n",
    "Now that we know what the data is, we need to make a plan for how to clean it:\n",
    "\n",
    "- Make sure that all dates in the date column are real dates and in the same format.\n",
    "- Remove all the `NaN` values from company, country and city.\n",
    "- Clean the price column by removing rows without a price and make sure all currencies are in euro. \n",
    "- Remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that all dates in the 'date' column are real dates and in the same format.\n",
    "\n",
    "Firstly, we find all the transactions with the default date format (_YYYY-MM-DD_). If a transaction is not in the default format it is changed to it. Further, if a date is a non-valid date it is removed (e.g. _2017-13-32_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_range = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    try:\n",
    "        # Default format of datetime\n",
    "        pd.to_datetime(df.iloc[i,4], format='%Y-%m-%d')\n",
    "    except:\n",
    "        try: \n",
    "            # Not default but still a valid datetime\n",
    "            df.iloc[i,4] = pd.to_datetime(df.iloc[i,4])\n",
    "        except:\n",
    "            # Non-valid datetime.\n",
    "            out_of_range.append(i)\n",
    "\n",
    "df.drop(out_of_range, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the type from `object` to `datetime64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company            object\n",
       "country            object\n",
       "city               object\n",
       "price              object\n",
       "date       datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = df['date'].astype('datetime64[ns]')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SUCCES!*** All dates are now changed to the same format and the type is changed to `datetime64`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all the NaN values from company, country and city.\n",
    "\n",
    "Firstly, we want to make sure that all countries are valid countries. \n",
    "\n",
    "We extract the latest information about current exsisting countries in the world from the external datasource: [World Bank Open Data](https://data.worldbank.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://api.worldbank.org/v2/sources/2/country/all/data?per_page=500&format=json&mrnev=1')\n",
    "json_response = r.json()\n",
    "res = json_response['source']\n",
    "\n",
    "list_country = []\n",
    "\n",
    "# Iterate to get the correct information from the json file\n",
    "for r in res:    \n",
    "    inner_res = r.get('concept')\n",
    "    for r in inner_res:\n",
    "        country = r.get('variable')\n",
    "        for r in country:\n",
    "            country = r.get('value')\n",
    "            list_country.append(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of true countries in the world has now been generated. \n",
    "\n",
    "Therefore, it is very easy to see which countries from our data set stand out and might not be real countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'US', 'Portuga', 'Tyskland']\n"
     ]
    }
   ],
   "source": [
    "not_real = []\n",
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,1] not in list_country:\n",
    "        not_real.append(df.iloc[i,1])\n",
    "\n",
    "print(list(set(not_real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, it is clear that John from finances made some typos while creating his excel-file. These typos are manually changed to the correct country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,1] == 'US':\n",
    "        df.iloc[i,1] = 'United States'\n",
    "    elif df.iloc[i,1] == 'Tyskland':\n",
    "        df.iloc[i,1] = 'Germany'\n",
    "    elif df.iloc[i,1] == 'Portuga':\n",
    "        df.iloc[i,1] = 'Portugal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since John from finances made typos in the country column, we wonder whether he also did the same thing in the company column. \n",
    "\n",
    "Unfortuneatly, no database of imagnianary companies is available so we have to be a bit creative in this exercise. \n",
    "\n",
    "We choose instead to count the number of times the company occurs in the dataframe and we make the assumption, that any company with a representation below or equal to 5 have to investigated further since these could be typos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' -', ' a', 'Laj0', 'Ntagz', 'Thoughtmixz', 'Zooxo.', 'aa']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = dict()\n",
    "weird_company = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,0] in counts:\n",
    "        counts[df.iloc[i,0]] += 1\n",
    "    else:\n",
    "        counts[df.iloc[i,0]] = 1    \n",
    "\n",
    "for char in sorted(counts.keys()):\n",
    "    if counts[char] <= 5:\n",
    "        weird_company.append(char)\n",
    "\n",
    "weird_company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, the companies listed look like possible typos. However, taking a quick glance at the dataframe with the remaining companies we see that some company names are almost identical. Thus we correct these companies to the right ones.\n",
    "\n",
    "_Note:_ Three companies still look weird (' -', ' a' and 'aa') and so far we do not have a solution. We will deal with these later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,0] == 'Zooxo.':\n",
    "        df.iloc[i,0] = 'Zooxo'\n",
    "    elif df.iloc[i,0] == 'Thoughtmixz':\n",
    "        df.iloc[i,0] = 'Thoughtmix'\n",
    "    elif df.iloc[i,0] == 'Ntagz':\n",
    "        df.iloc[i,0] = 'Ntags'\n",
    "    elif df.iloc[i,0] == 'Laj0':\n",
    "        df.iloc[i,0] = 'Lajo' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are sure we got rid of all of John's typos, we group each company by its country.\n",
    "\n",
    "We assume that three cases will be present:\n",
    "\n",
    "    (I): There is only one country for the company. In this case nothing is done. \n",
    "    (II): There is one country and one NaN value for the company. Here we replace the NaN value with the country.\n",
    "    (III): There are multiple countries for the company (and possible also NaN values). This is an odd case and we have to investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flipstorm']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('company')['country'].unique().apply(list).to_dict()\n",
    "\n",
    "still_weird_company = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    # If a NaN value is present\n",
    "    if pd.isna(df.iloc[i,1]) == True:\n",
    "        # Replace NaN value with country\n",
    "        if len(grouped[df.iloc[i,0]]) == 2:\n",
    "            df.iloc[i,1] = grouped[df.iloc[i,0]][0]\n",
    "        # Store odd cases in list\n",
    "        elif len(grouped[df.iloc[i,0]]) >= 2:\n",
    "            still_weird_company.append(df.iloc[i,0])\n",
    "            \n",
    "list(set(still_weird_company))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SUCCES!*** All companies (except 'Flipstorm') now have one country and no `NaN` value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to group each company by its country and city.\n",
    "\n",
    "We assume that three cases will be present:\n",
    "\n",
    "    (I): There is one country and one city for the company. In this case nothing is done. \n",
    "    (II): There is one country, one city and one NaN value for the company. In that case\n",
    "    nothing is done just yet. \n",
    "    (III): There are multiple countries and/or multiple cities for this company (and \n",
    "    possible also NaN values). This is an odd case and we have to investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Greece', 'Athens', 'France', 'Nanterre', nan], ['Portugal', 'Braga', nan, 'Monção'], ['Portugal', 'Amadora\\t', 'Vila Fria', nan]]\n"
     ]
    }
   ],
   "source": [
    "grouped = (df.groupby(['company'])['country', 'city']\n",
    "       .apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
    "\n",
    "weird_city = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    # Store odd cases in list\n",
    "    if len(grouped[df.iloc[i,0]]) > 3:\n",
    "        if grouped[df.iloc[i,0]] in weird_city:\n",
    "            pass\n",
    "        else:\n",
    "            weird_city.append(grouped[df.iloc[i,0]])\n",
    "\n",
    "print(weird_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above result, we see three cases that stand out from the rest.\n",
    "\n",
    "After a quick google search we realize that John from finances once again made a mistake (_Oh John_). Vila Fria and Monção are not cities but areas and these are changed to the correct cities.\n",
    "\n",
    "_Note:_ We also removed the extra /t from Amadora. \n",
    "\n",
    "Furthermore, if the country is Greece or France, the city should be Athens or Nanterre, respectively, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,2] == 'Amadora\\t':\n",
    "        df.iloc[i,2] = 'Amadora'\n",
    "    elif df.iloc[i,2] == 'Vila Fria':\n",
    "        df.iloc[i,2] = 'Amadora'\n",
    "    elif df.iloc[i,2] == 'Monção':\n",
    "        df.iloc[i,2] = 'Braga'\n",
    "        \n",
    "    elif df.iloc[i,1] == 'Greece':\n",
    "        df.iloc[i,2] = 'Athens'\n",
    "    elif df.iloc[i,1] == 'France':\n",
    "        df.iloc[i,2] = 'Nanterre'\n",
    "    elif df.iloc[i,2] == 'Athens':\n",
    "        df.iloc[i,1] = 'Greece'\n",
    "    elif df.iloc[i,2] == 'Nanterre':\n",
    "        df.iloc[i,1] = 'France'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is fixed, the companies are grouped together once more.\n",
    "\n",
    "This time we focus on all the cases where there is one country, one city and one NaN value for the company. Here we replace the NaN value with the city since we earlier made sure that there was no NaN value in the country column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (df.groupby(['company'])['country', 'city']\n",
    "       .apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    # If a NaN value is present\n",
    "    if pd.isna(df.iloc[i,2]) == True:\n",
    "        # Replace NaN value with city\n",
    "        if len(grouped[df.iloc[i,0]]) == 3:\n",
    "            df.iloc[i,2] = grouped[df.iloc[i,0]][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sigh of relief leaves our body. _Done_, we think to ourself.\n",
    "\n",
    "But suddenly we remember the three weird companies ' -', ' a', and 'aa'. \n",
    "\n",
    "We wonder if John's typos are so severe that these companies actually are some other company hidden under a typo. To check this, we see if the location of the company is identical to some of the other companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (df.groupby(['company'])['country', 'city']\n",
    "       .apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
    "\n",
    "weird_company = ['aa',' a',' -']\n",
    "\n",
    "for j in weird_company:\n",
    "    weird = grouped[j]\n",
    "    for i in range(len(grouped)):\n",
    "        if grouped[i] == weird and grouped.keys()[i] not in weird_company:\n",
    "            print('The company placement of \"%s\" matches the company \"%s\".' % (j, grouped.keys()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each company location only matches one other company's. Thus we make the assumption that these companies are the same. This is corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,0] == 'aa':\n",
    "        df.iloc[i,0] = 'Wordify'\n",
    "    elif df.iloc[i,0] == ' a':\n",
    "        df.iloc[i,0] = 'Wordify'\n",
    "    elif df.iloc[i,0] == ' -':\n",
    "        df.iloc[i,0] = 'Zoonder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do a final status overview to check if everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (df.groupby(['company'])['country', 'city']\n",
    "       .apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PERFECT!!!!*** No more `NaN` values!\n",
    "\n",
    "But suddenly we remember yesterday's news program. Some companies have been caught cheating on their taxes by locating their company in non-existing cities. \n",
    "\n",
    "Sleepless we dive into this task. We find a json file containing almost all countries with their respective cities: [All countries and cities](https://raw.githubusercontent.com/russ666/all-countries-and-cities-json/6ee538beca8914133259b401ba47a550313e8984/countries.json). We realize that this list is not updated often but since countries rarely change and new cities rarely arise we feel it is safe to work with this file.\n",
    "\n",
    "We then store each country and its cities in a `dict()` and iterate our dataframe over the `dict()` to find suspicious cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://raw.githubusercontent.com/russ666/all-countries-and-cities-json/6ee538beca8914133259b401ba47a550313e8984/countries.json')\n",
    "json_response = r.json()\n",
    "res = json_response\n",
    "res\n",
    "\n",
    "weird_countries = {}\n",
    "\n",
    "country_list = {}\n",
    "\n",
    "# Store country and cities in a dict().\n",
    "for r in res:\n",
    "    country_list[r] = res[r]\n",
    "    \n",
    "for i in range(0,len(df)):\n",
    "    # Iterate over the country.\n",
    "    if df.iloc[i,1] in country_list.keys():\n",
    "        country = str(df.iloc[i,1])\n",
    "        # Iterate over the city.\n",
    "        if df.iloc[i,2] not in country_list[country]:\n",
    "            weird_countries[df.iloc[i,1]] = df.iloc[i,2]\n",
    "\n",
    "print(weird_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a glance (and a google search) all our worries are put to shame. All the suspicious cities from above are real and placed in the right country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the 'price' column by removing rows without a price and make sure all currencies are in euro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a short break and some coffee we are back at our desk ready to tackle the next task: Cleaning up the price column. \n",
    "\n",
    "Firtly, we want to find all the values that are not real transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removable = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    price = str(df.iloc[i,3])\n",
    "\n",
    "    regex = re.search(r\"\\-?\\d+\\.\\d{,3}\", price)\n",
    "        \n",
    "    if regex is None:\n",
    "        removable.append(price)\n",
    "            \n",
    "list(set(removable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transactions with the above words/symbols in the price column seem safe to remove and that is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_price = []\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row['price']) == True or row['price'] == '-' or row['price'] == 'na' or row['price'] == 'void':\n",
    "        remove_price.append(index)\n",
    "df.drop(remove_price, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the task of cleaning up the transactions, we need to get everything in the same currency (_euro €_). \n",
    "\n",
    "Since exchange rates can fluctuate tremendously we need to get the correct value at the correct date. Thus we need to get our information from an external source: [Exchange rates API](http://exchangeratesapi.io).\n",
    "\n",
    "We make a `dict()` containing all exchange rates for all available currencies from 2000 to 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.exchangeratesapi.io/history?start_at=2000-01-01&end_at=2019-10-08')\n",
    "json_response = r.json()\n",
    "\n",
    "rates = json_response['rates']\n",
    "\n",
    "real_dates = []\n",
    "\n",
    "for dates in rates:\n",
    "    real_dates.append(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the above exchange rates API only works with currency codes and not currency symbols we need som information from an external source in order to translate from one to the another. We use the json file: [Common currency](https://gist.githubusercontent.com/Fluidbyte/2973986/raw/b0d1722b04b0a737aade2ce6e055263625a0b435/Common-Currency.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://gist.githubusercontent.com/Fluidbyte/2973986/raw/b0d1722b04b0a737aade2ce6e055263625a0b435/Common-Currency.json')\n",
    "json_response = r.json()\n",
    "\n",
    "aDict = {}\n",
    "for r in json_response: \n",
    "    aDict[json_response[r]['symbol']] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now iterate over every single transaction.\n",
    "\n",
    "If a transaction has a € at the end, the currency symbol is simply removed.\n",
    "\n",
    "If a transaction has a any other cuurency symbol than €, the symbol is translated to the currency code. Furthermore, the date of the transaction is looked up in the former made `dict()`. If the date is in the `dict()` the date is kept, if not, the date is minused by one until at date in the `dict()` is found. The currency code and the date is used to find the correct exchange rate in the `dict()`. The currency symbol is removed from the transaction and the transaction amount are divided by the exchange rate.\n",
    "\n",
    "If a transaction do not have a currency symbol it is removed from the transaction dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_currency = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    try:\n",
    "        original_price = df.iloc[i,3]\n",
    "\n",
    "        regex = re.search(r\"^\\-?\\d+\\.\\d{,3}\\€{1}\", original_price)\n",
    "\n",
    "        # If the currency has a € at the end        \n",
    "        if regex is not None:\n",
    "            price = float(df.iloc[i,3][:-1])\n",
    "            df.iloc[i,3] = round(price,2)\n",
    "\n",
    "        elif regex is None:\n",
    "            # Find the currency symbol            \n",
    "            non_digit = re.search(r'\\D',df.iloc[i,3])\n",
    "            non_digit = non_digit.group(0)\n",
    "\n",
    "            # Find the date\n",
    "            date = str(df.iloc[i,4])\n",
    "            date = date[:-9]\n",
    "\n",
    "            # Transform currency symbol to currency code \n",
    "            currency = aDict[non_digit]\n",
    "\n",
    "            # If the currency is not update at the date given \n",
    "            while date not in real_dates:\n",
    "                date = pd.to_datetime(date)\n",
    "                # Minus the date by a day\n",
    "                date = date - pd.Timedelta(days=1)\n",
    "                date = str(date)\n",
    "                date = date[:-9]\n",
    "\n",
    "            # Look up the rate at the given date and currency code\n",
    "            rate = rates[date][currency]\n",
    "\n",
    "            price = float(df.iloc[i,3][1:]) / rate\n",
    "            df.iloc[i,3] = round(price,2)  \n",
    "            \n",
    "    # If the transaction do not have a currency.      \n",
    "    except:\n",
    "        no_currency.append(i)\n",
    "\n",
    "# Remove if no currency attached. \n",
    "df.drop(no_currency, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note:_ If time had allowed it, we would have checked from which country the dropped transactions came from and used an external database to translate from country to correct currency code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the price column is changed to `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = pd.to_numeric(df['price'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Yippie-ki-yay*** It worked! All transaction prices are now transformed to a `float64` and much easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates.\n",
    "\n",
    "If John from finances by mistake has entered as transaction twice, this would be corrected by removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Status.\n",
    "\n",
    "The data has been cleaned and is now ready for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_rows = len(df)\n",
    "start_rows - end_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, 17 rows have been removed from the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task for a data scientists is to combine or enrich data from internal sources with data available from external sources. The purpose of this can be either to fix issues with the data or to make it easier to derive insights from the data.\n",
    "\n",
    "In this part you should enrich your data with data from at least one external source. You may look to part 4 for some  inspiration as to what is required. Your solution should be automated, i.e., you can not ask the reader of your notebook to download any data manually. You should argue why and what you expect to achieve by the enrichments you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In _Part 1: Cleaning the data_ we have already used multiple external sources to enrich our data.\n",
    "\n",
    "***Countries:*** We extracted the latest information about current exsisting countries in the world from the external datasource: [World Bank Open Data](https://data.worldbank.org). \n",
    "\n",
    "This was done to ensure that all countries were real countries, not just typos or imaginary once. \n",
    "\n",
    "***Cities:*** We found a json file containing almost all countries with their respective cities ([All countries and cities](https://raw.githubusercontent.com/russ666/all-countries-and-cities-json/6ee538beca8914133259b401ba47a550313e8984/countries.json))\n",
    "\n",
    "This was done to ensure that all cities were real cities, not just typos or imaginary once. Furthermore, it was done to ensure that the city was placed in its respective country. \n",
    "\n",
    "***Currency***: We found a json file for transforming currency symbols to currency codes ([Common currency](https://gist.githubusercontent.com/Fluidbyte/2973986/raw/b0d1722b04b0a737aade2ce6e055263625a0b435/Common-Currency.json)) and used another external source to get the exact exchange rate at the correct date with the correct currency code ([Exchange rates API](http://exchangeratesapi.io)).\n",
    "\n",
    "This was done to ensure that all transaction prices were converted to the same currency (euro) and since exchange rates can fluctuate tremendously we need to get the correct rate otherwise the price would be misleading.\n",
    "\n",
    "***GDP (current US$)***: In this part (_Part 2: Enriching the data_) of the exercises we have decide to include an extra column with the information about a countries GDP. This information was extracted from the external source: [World Bank Open Data](https://data.worldbank.org). The information extracted is the latest information available for each country. \n",
    "\n",
    "This was done to get information about the richness of a country and to see how big a sum of the overall GDP of a country is used on gatged. This information can be used to target the countries that spend the least amout of their GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://api.worldbank.org/v2/sources/2/country/all/series/NY.GDP.MKTP.CD/data?per_page=500&format=json&mrnev=1')\n",
    "json_response = r.json()\n",
    "res = json_response['source']['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the country and a list with its GDP (current US$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_country = []\n",
    "list_value_GDP_dollar = []\n",
    "\n",
    "counter = 0\n",
    "for r in res:\n",
    "    inner_res = r.get('variable')\n",
    "    value = r.get('value')\n",
    "\n",
    "    list_value_GDP_dollar.append(value)\n",
    "    \n",
    "    for r in inner_res:\n",
    "        country = r.get('value')\n",
    "        list_country.append(country)\n",
    "        break\n",
    "\n",
    "unique_country = []\n",
    "for country in list_country:\n",
    "    if country not in unique_country:\n",
    "        unique_country.append(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the information about the latest exchange rate for USD currency to EURO currency from the external source: [Exchange rates API](http://exchangeratesapi.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.exchangeratesapi.io/latest?symbols=USD')\n",
    "json_response = r.json()\n",
    "\n",
    "rates = json_response['rates']['USD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the USD GDP to EURO GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_value_GDP_euro = []\n",
    "for i in list_value_GDP_dollar:\n",
    "    list_value_GDP_euro.append(i*rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the country list and the GDP (current EURO) list together into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(list(zip(unique_country,list_value_GDP_euro)), columns =['country','gdp_euro'])\n",
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, new_df, on='country', how='inner')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the original dataframe showing transaction together with the new dataframe. They are merged together using country as the merge mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sqlite3\n",
    "\n",
    "# Set up the sqlite database file\n",
    "conn = sqlite3.connect('transactions.sqlite')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.to_sql` takes the dataframe transaction and convert it into a database for `sqlite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(\"transactions\", conn, if_exists='replace')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe _transaction_ is converted into a database to be used in `sqlite`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('SELECT company, SUM(price) FROM transactions GROUP BY company ORDER BY SUM (price) DESC;') \n",
    "c.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('SELECT company,price,date FROM transactions GROUP BY date ORDER BY company;')\n",
    "data = c.fetchall()\n",
    "#data\n",
    "\n",
    "c.execute('SELECT DISTINCT company FROM transactions ORDER BY company;')\n",
    "companies = c.fetchall()\n",
    "\n",
    "c.execute('SELECT company,avg(price),strftime(\"%Y-%m\", date) FROM transactions GROUP BY company,strftime(\"%Y-%m\", date) ORDER BY company;')\n",
    "datasmall = c.fetchall()\n",
    "#datasmall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, the plots showing the prices for all transactions are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,12))\n",
    "\n",
    "i = 0\n",
    "\n",
    "values = []\n",
    "dates = []\n",
    "legend = []\n",
    "\n",
    "for row in data:\n",
    "    if row[0]==companies[i][0]:\n",
    "        values.append(row[1])\n",
    "        datestimes = datetime.strptime(row[2],'%Y-%m-%d %H:%M:%S')\n",
    "        dates.append(datestimes)\n",
    "    else:\n",
    "        legend.append(companies[i][0])\n",
    "        plt.plot(dates,values,'-')\n",
    "        i+=1\n",
    "        values = []\n",
    "        dates = []\n",
    "\n",
    "plt.legend(legend,loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, the plots showing the average prices for each month each year are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,12))\n",
    "\n",
    "i = 0\n",
    "\n",
    "values = []\n",
    "dates = []\n",
    "legend = []\n",
    "\n",
    "for row in datasmall:\n",
    "    if row[0]==companies[i][0]:\n",
    "        values.append(row[1])\n",
    "        datestimes = datetime.strptime(row[2],'%Y-%m')\n",
    "        dates.append(datestimes)\n",
    "    else:\n",
    "        legend.append(companies[i][0])\n",
    "        plt.plot(dates,values,'-')\n",
    "        i+=1\n",
    "        values = []\n",
    "        dates = []\n",
    "\n",
    "plt.legend(legend,loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, linear regressions are made for each company and these are shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,12))\n",
    "\n",
    "i = 0\n",
    "values = []\n",
    "dates = []\n",
    "coeflist = []\n",
    "legend = []\n",
    "\n",
    "for row in data:\n",
    "    if row[0]==companies[i][0]:\n",
    "        values.append(row[1])\n",
    "        datestimes = datetime.strptime(row[2],'%Y-%m-%d %H:%M:%S')\n",
    "        datestimes = datetime.timetuple(datestimes)\n",
    "        dates.append(time.mktime(datestimes))\n",
    "    else:\n",
    "        x = np.asarray(dates).reshape((-1,1))\n",
    "        y = np.asarray(values)  \n",
    "        model = LinearRegression().fit(x,y)\n",
    "        score = model.score(x,y)\n",
    "        intercept = model.intercept_\n",
    "        coef = model.coef_[0]\n",
    "        coeflist.append(coef)\n",
    "        legend.append(companies[i][0])\n",
    "        plt.plot(x,coef*x + intercept)\n",
    "        i+=1\n",
    "        values = []\n",
    "        dates = []\n",
    "        #print(\"Company: {}\\nScore: {}\\nIntercept: {}\\nCoefficient: {}\\n\".format(companies[i][0],score[0],intercept[0],coef[0]))\n",
    "\n",
    "plt.legend(legend,loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "matrix=np.array([legend,coeflist]).T\n",
    "df = pd.DataFrame(matrix,columns=[\"Company\",\"Profit forecast\"])\n",
    "print(df.sort_values(by=\"Profit forecast\",ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which countries do we proportionally have the smallest market in? \n",
    "\n",
    "Knowing which country spends the least of its GDP on the gadget market can tell us two things: (I) Either the country do not use as many gadget or (II) the clients get there gadgets from another company. \n",
    "\n",
    "Answering this question can tell company X were they need to target customers more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('SELECT SUM (price)/gdp_euro*100, country FROM transactions GROUP BY country ORDER BY SUM (price)/gdp_euro*100;')\n",
    "c.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***How much on average do we sell in a specific month?***\n",
    "\n",
    "Knowing what we approximeatly sell each month can help the company restock inventory before a big sales month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.execute('SELECT strftime(\"%Y-%m\",date),Avg(price) FROM transactions GROUP BY strftime(\"%Y-%m\",date);')\n",
    "\n",
    "c.execute('SELECT strftime(\"%m\",date), sum(price) from transactions GROUP BY strftime(\"%m\",date);')\n",
    "\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the average sale per month are stable throughout the year. The companies inventory simply has to stay at the same level all time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Has the sale been declining since the beginning of the company?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('SELECT strftime(\"%Y\",date),SUM(price) FROM transactions GROUP BY strftime(\"%Y\",date);')\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meeting revenue goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guide to the format \n",
    "#X = \"Company name\"\n",
    "#t1 = \"YYYY-MM-DD\"\n",
    "#t2 = \"YYYY-MM-DD\"\n",
    "\n",
    "# Example \n",
    "X = \"Gevee\"\n",
    "t1 = \"2017-01-12\"\n",
    "t2 = \"2017-05-02\"\n",
    "\n",
    "c.execute('SELECT company, price, date FROM transactions WHERE company = \"%s\" AND date BETWEEN \"%s\" and \"%s\";' % (X,t1,t2))\n",
    "newdata = c.fetchall()\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guide to the format \n",
    "#X = \"Company name\"\n",
    "#day = \"YYYY-MM-DD\"\n",
    "\n",
    "# Example \n",
    "X = \"Gevee\"\n",
    "day = \"2017-03-15\"\n",
    "\n",
    "#c.execute('SELECT company,SUM(price),date FROM transactions WHERE company = \"%s\" AND date = \"%s\";' % (X,day))\n",
    "c.execute('SELECT company,sum(price),strftime(\"%Y-%m-%d\", date) FROM transactions WHERE company = \"Gevee\" AND date = \"2017-03-15\" GROUP BY strftime(\"%Y-%m-%d\", date);')\n",
    "c.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "day = \"2017-03-15\"\n",
    "\n",
    "c.execute('SELECT price,date FROM transactions WHERE date = \"%s\";' % (day))\n",
    "#c.execute('SELECT SUM(price),strftime(\"%Y-%m-%d\", date) FROM transactions GROUP BY strftime(\"%Y-%m-%d\", date) ORDER BY strftime(\"%Y-%m-%d\", date);')\n",
    "newdata = c.fetchall()\n",
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Show the latest X sales in the database***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_sales = 10\n",
    "\n",
    "c.execute('SELECT company,price,date FROM transactions ORDER BY date DESC LIMIT %s' % number_sales)\n",
    "\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
