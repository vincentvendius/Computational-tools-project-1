{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Customer Database\n",
    "**This is the first of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Your team has been hired by the company X as data scientists. X makes gadgets for a wide range of industrial and commercial clients.\n",
    "\n",
    "As in-house data scientists, your teams first task, as per request from your new boss, is to optimize business operations. You have decided that a good first step would be to analyze the companys historical sales data to gain a better understanding of where profit is coming from. It may also reveal some low hanging fruit in terms of business opportunities.\n",
    "\n",
    "To get started, you have called the IT department to get access to the customer and sales transactions database. To your horror you've been told that such a database doens't exist, and the only record of sales transactions is kept by John from finance in an Excel spreadsheet. So you've emailed John asking for a CSV dump of the spreadsheet...\n",
    "\n",
    "In this project you need to clean the data you got from John, enrich it with further data, prepare a database for the data, and do some data analysis. The project is comprised of five parts. They are intended to be solved in the order they appear, but it is highly recommended that you read through all of them and devise an overall strategy before you start implementing anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning the data\n",
    "John has emailed you the following link to the CSV dump you requested.\n",
    "\n",
    "- [transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)\n",
    "\n",
    "It seems as though he has been a bit sloppy when keeping the records. \n",
    "\n",
    "In this part you should:\n",
    "- Explain what the data is\n",
    "- Clean it to prepare it for inserting into a database and doing data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the CSV file given to us by John from finances, a large table can be found. \n",
    "\n",
    "Each row represents a transaction from a sale of gadgets to a company. \n",
    "\n",
    "The file is loaded to get more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company country          city    price  \\\n",
       "0  54868-5165  Chatterbridge   Spain     Barcelona  784.79€   \n",
       "1  60505-2867           Lajo  Greece  Thessaloniki  187.99€   \n",
       "2   24385-268      Flipstorm  Greece        Athens  221.73€   \n",
       "\n",
       "                  date  \n",
       "0  2016-01-02 00:01:05  \n",
       "1  2016-01-02 00:05:26  \n",
       "2  2016-01-02 00:18:30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('transactions.csv', encoding='utf-8-sig')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20568"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_rows = len(df)\n",
    "start_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table consists of 20568 data rows and there are 6 columns of information for each transaction. \n",
    "\n",
    "The first column, 'part', is not unique nor does it give information important in regards to doing this exercise. Therefore, it is removed from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company country          city    price                 date\n",
       "0  Chatterbridge   Spain     Barcelona  784.79€  2016-01-02 00:01:05\n",
       "1           Lajo  Greece  Thessaloniki  187.99€  2016-01-02 00:05:26\n",
       "2      Flipstorm  Greece        Athens  221.73€  2016-01-02 00:18:30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['part'], inplace=True, axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain a better knowledge of the type of data, the first order of business is to have python tell us what type of data we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company    object\n",
       "country    object\n",
       "city       object\n",
       "price      object\n",
       "date       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output tells us that the data in all the columns is of 'object' type - also known as 'string' type. However, from the table it is clear that the data in the 'price' and 'date' columns should not be an object but rather a float and datetime, respectively. \n",
    "\n",
    "Now when we know what the data is, we need to make a plan for how to clean it:\n",
    "\n",
    "- Make sure that all dates in the 'date' column are real dates and in the same format.\n",
    "- Remove all the NaN values from company, country and city.\n",
    "- Clean the 'price' column by removing rows without a price and make sure all currencies are in euro. \n",
    "- Remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that all dates in the 'date' column are real dates and in the same format.\n",
    "\n",
    "***I:*** We find the transactions with the default date format. If a transaction is not in the default format it is changed to it. Further, if a date is a non-valid date it is removed (e.g. 2017-13-32). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_range = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    try:\n",
    "        pd.to_datetime(df.iloc[i,4], format='%Y-%m-%d')\n",
    "    except:\n",
    "        try: \n",
    "            df.iloc[i,4] = pd.to_datetime(df.iloc[i,4])\n",
    "        except:\n",
    "            out_of_range.append(i)\n",
    "\n",
    "df.drop(out_of_range, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***II:*** We change the dtype from object to datetime64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company            object\n",
       "country            object\n",
       "city               object\n",
       "price              object\n",
       "date       datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = df['date'].astype('datetime64[ns]')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SUCCES!*** All dates are now changed to the same format and the dtype is changed to datetime64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all the NaN values from company, country and city.\n",
    "\n",
    "***I:*** We check which companies are unique in which countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' -': ['United States'], ' a': ['United States'], 'Avaveo': ['France', nan], 'Brainsphere': ['Portugal', nan, 'Portuga'], 'Bubblemix': ['Japan', nan], 'Buzzbean': ['Germany', nan, 'Tyskland'], 'Chatterbridge': ['Spain', nan], 'Eimbee': ['France', nan], 'Flipstorm': ['Greece', 'France', nan], 'Gabcube': ['Portugal', nan], 'Gabtune': ['France', nan], 'Gevee': ['France', nan], 'Innojam': ['Netherlands', nan], 'Kanoodle': ['Japan', nan], 'Laj0': ['Greece'], 'Lajo': ['Greece', nan], 'Ntags': ['Portugal', nan, 'Portuga'], 'Ntagz': ['Portugal'], 'Realpoint': ['Portugal', nan], 'Rhycero': ['France', nan], 'Riffpath': ['Greece', nan], 'Roodel': ['Portugal', nan], 'Shufflebeat': ['Portugal', nan], 'Tagtune': ['Switzerland', nan], 'Teklist': ['Netherlands', nan], 'Thoughtmix': ['Portugal', nan, 'Portuga'], 'Thoughtmixz': ['Portugal'], 'Twitterbeat': ['France', nan], 'Voomm': ['France', nan], 'Wordify': ['United States', nan], 'Yozio': ['Greece', nan], 'Zoonder': ['United States', 'US', nan], 'Zooxo': ['United Kingdom', nan], 'Zooxo.': ['United Kingdom'], 'aa': ['United States']}\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('company')['country'].unique().apply(list).to_dict()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***II:*** We see that some companies and countries are close to identical and we figure that these must be typos. These are corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,0] == 'Zooxo.':\n",
    "        df.iloc[i,0] = 'Zooxo'\n",
    "    elif df.iloc[i,0] == 'Thoughtmixz':\n",
    "        df.iloc[i,0] = 'Thoughtmix'\n",
    "    elif df.iloc[i,0] == 'Ntagz':\n",
    "        df.iloc[i,0] = 'Ntags'\n",
    "    elif df.iloc[i,0] == 'Laj0':\n",
    "        df.iloc[i,0] = 'Lajo'\n",
    "    elif df.iloc[i,1] == 'US':\n",
    "        df.iloc[i,1] = 'United States'\n",
    "    elif df.iloc[i,1] == 'Tyskland':\n",
    "        df.iloc[i,1] = 'Germany'\n",
    "    elif df.iloc[i,1] == 'Portuga':\n",
    "        df.iloc[i,1] = 'Portugal'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('company')['country'].unique().apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***III:*** Most of the companies now only have one country and a NaN value in the 'country' column. Therefore, we make the assumption that in these cases the company is only located in one specific country. All the NaN value are switched to this specific country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if pd.isna(df.iloc[i,1]) == True:\n",
    "        if len(grouped[df.iloc[i,0]]) == 2:\n",
    "            df.iloc[i,1] = grouped[df.iloc[i,0]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SUCCES!*** Most companies (except 'Flipstorm') now only have one country and no NaN value should be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' -': ['United States'],\n",
       " ' a': ['United States'],\n",
       " 'Avaveo': ['France'],\n",
       " 'Brainsphere': ['Portugal'],\n",
       " 'Bubblemix': ['Japan'],\n",
       " 'Buzzbean': ['Germany'],\n",
       " 'Chatterbridge': ['Spain'],\n",
       " 'Eimbee': ['France'],\n",
       " 'Flipstorm': ['Greece', 'France', nan],\n",
       " 'Gabcube': ['Portugal'],\n",
       " 'Gabtune': ['France'],\n",
       " 'Gevee': ['France'],\n",
       " 'Innojam': ['Netherlands'],\n",
       " 'Kanoodle': ['Japan'],\n",
       " 'Lajo': ['Greece'],\n",
       " 'Ntags': ['Portugal'],\n",
       " 'Realpoint': ['Portugal'],\n",
       " 'Rhycero': ['France'],\n",
       " 'Riffpath': ['Greece'],\n",
       " 'Roodel': ['Portugal'],\n",
       " 'Shufflebeat': ['Portugal'],\n",
       " 'Tagtune': ['Switzerland'],\n",
       " 'Teklist': ['Netherlands'],\n",
       " 'Thoughtmix': ['Portugal'],\n",
       " 'Twitterbeat': ['France'],\n",
       " 'Voomm': ['France'],\n",
       " 'Wordify': ['United States'],\n",
       " 'Yozio': ['Greece'],\n",
       " 'Zoonder': ['United States'],\n",
       " 'Zooxo': ['United Kingdom'],\n",
       " 'aa': ['United States']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('company')['country'].unique().apply(list).to_dict()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IV:*** We now check which companies are unique in which countries AND cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       " -                               [United States, Boston]\n",
       " a                             [United States, New York]\n",
       "Avaveo                                    [France, Nice]\n",
       "Brainsphere               [Portugal, Braga, nan, Monção]\n",
       "Bubblemix                                 [Japan, Asaka]\n",
       "Buzzbean                           [Germany, Düsseldorf]\n",
       "Chatterbridge                         [Spain, Barcelona]\n",
       "Eimbee                                  [France, Amiens]\n",
       "Flipstorm        [Greece, Athens, France, Nanterre, nan]\n",
       "Gabcube                               [Portugal, Almada]\n",
       "Gabtune                                   [France, Lyon]\n",
       "Gevee                              [France, Champagnole]\n",
       "Innojam                         [Netherlands, Amsterdam]\n",
       "Kanoodle                           [Japan, Niihama, nan]\n",
       "Lajo                              [Greece, Thessaloniki]\n",
       "Ntags                            [Portugal, Lisbon, nan]\n",
       "Realpoint                             [Portugal, Lisbon]\n",
       "Rhycero                                [France, Arcueil]\n",
       "Riffpath                             [Greece, Heraklion]\n",
       "Roodel                               [Portugal, Aranhas]\n",
       "Shufflebeat                       [Portugal, Porto, nan]\n",
       "Tagtune                            [Switzerland, Zürich]\n",
       "Teklist                       [Netherlands, Arnhem, nan]\n",
       "Thoughtmix         [Portugal, Amadora\\t, Vila Fria, nan]\n",
       "Twitterbeat                        [France, Annecy, nan]\n",
       "Voomm                                    [France, Paris]\n",
       "Wordify                   [United States, New York, nan]\n",
       "Yozio                              [Greece, Patras, nan]\n",
       "Zoonder                     [United States, Boston, nan]\n",
       "Zooxo                      [United Kingdom, London, nan]\n",
       "aa                             [United States, New York]\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = (df.groupby(['company'])['country', 'city']\n",
    "       .apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dream scenario of having a company in only one country and one city is far from fulfilled. \n",
    "\n",
    "***V:*** Three companies, 'aa', ' a' and ' -', seem suspicious. For each of these companies it is clear that only one other company has the exact same location. Tus, we assume that the three suspicious companies are actually typos of the companies with the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,0] == 'aa':\n",
    "        df.iloc[i,0] = 'Wordify'\n",
    "    elif df.iloc[i,0] == ' a':\n",
    "        df.iloc[i,0] = 'Wordify'\n",
    "    elif df.iloc[i,0] == ' -':\n",
    "        df.iloc[i,0] = 'Zoonder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***VI:*** We see that the company 'Brainsphere' is in two different cities in Portugal. So we count how many times the company occurs in each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Braga: 1237\n",
      "Monção: 1\n"
     ]
    }
   ],
   "source": [
    "count_braga = count_moncao = 0\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,2] == 'Braga':\n",
    "        count_braga += 1\n",
    "    elif df.iloc[i,2] == 'Monção':\n",
    "        count_moncao += 1\n",
    "        \n",
    "print('Braga: %s\\nMonção: %s' % (count_braga, count_moncao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***VII:*** It is now clear that John from finances made a mistake since 'Brainspehere' is only found once in Monção. So we change the city from Monção to Braga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,2] == 'Monção':\n",
    "        df.iloc[i,2] = 'Braga'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***VIII:*** We see that the company 'Thoughtmix' is in two different cities in Portugal. But after a quick google search we realize that John from finances once again made a mistake. Vila Fria is not a city but an area in Amadora and thus we changed it to Amadora. Note: We also removed the extra /t from Amadora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.iloc[i,2] == 'Amadora\\t':\n",
    "        df.iloc[i,2] = 'Amadora'\n",
    "    elif df.iloc[i,2] == 'Vila Fria':\n",
    "        df.iloc[i,2] = 'Amadora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "Avaveo                                    [France, Nice]\n",
       "Brainsphere                       [Portugal, Braga, nan]\n",
       "Bubblemix                                 [Japan, Asaka]\n",
       "Buzzbean                           [Germany, Düsseldorf]\n",
       "Chatterbridge                         [Spain, Barcelona]\n",
       "Eimbee                                  [France, Amiens]\n",
       "Flipstorm        [Greece, Athens, France, Nanterre, nan]\n",
       "Gabcube                               [Portugal, Almada]\n",
       "Gabtune                                   [France, Lyon]\n",
       "Gevee                              [France, Champagnole]\n",
       "Innojam                         [Netherlands, Amsterdam]\n",
       "Kanoodle                           [Japan, Niihama, nan]\n",
       "Lajo                              [Greece, Thessaloniki]\n",
       "Ntags                            [Portugal, Lisbon, nan]\n",
       "Realpoint                             [Portugal, Lisbon]\n",
       "Rhycero                                [France, Arcueil]\n",
       "Riffpath                             [Greece, Heraklion]\n",
       "Roodel                               [Portugal, Aranhas]\n",
       "Shufflebeat                       [Portugal, Porto, nan]\n",
       "Tagtune                            [Switzerland, Zürich]\n",
       "Teklist                       [Netherlands, Arnhem, nan]\n",
       "Thoughtmix                      [Portugal, Amadora, nan]\n",
       "Twitterbeat                        [France, Annecy, nan]\n",
       "Voomm                                    [France, Paris]\n",
       "Wordify                   [United States, New York, nan]\n",
       "Yozio                              [Greece, Patras, nan]\n",
       "Zoonder                     [United States, Boston, nan]\n",
       "Zooxo                      [United Kingdom, London, nan]\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = (df.groupby(['company'])['country', 'city']\n",
    "       .apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IX:*** Most of the companies now only have one specific country, one specific city and a NaN value in the 'city' column (except the company 'Flipstorm'). All the NaN values are switched to the specific city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if pd.isna(df.iloc[i,2]) == True:\n",
    "        if len(grouped[df.iloc[i,0]]) == 3:\n",
    "            df.iloc[i,2] = grouped[df.iloc[i,0]][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***X:*** Now only the company 'Flipstorm' is messed up. This is easiely fixed. If the country is Greece the city should be Athens, and vice versa. If the country is France the city should be Nanterre, and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in range(0,len(df)):\n",
    "    if df.iloc[i,1] == 'Greece':\n",
    "        df.iloc[i,2] = 'Athens'\n",
    "    elif df.iloc[i,1] == 'France':\n",
    "        df.iloc[i,2] = 'Nanterre'\n",
    "    elif df.iloc[i,2] == 'Athens':\n",
    "        df.iloc[i,1] = 'Greece'\n",
    "    elif df.iloc[i,2] == 'Nanterre':\n",
    "        df.iloc[i,1] = 'France'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XI:*** We do a final check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "Avaveo                           [France, Nanterre]\n",
       "Brainsphere                       [Portugal, Braga]\n",
       "Bubblemix                            [Japan, Asaka]\n",
       "Buzzbean                      [Germany, Düsseldorf]\n",
       "Chatterbridge                    [Spain, Barcelona]\n",
       "Eimbee                           [France, Nanterre]\n",
       "Flipstorm        [Greece, Athens, France, Nanterre]\n",
       "Gabcube                          [Portugal, Almada]\n",
       "Gabtune                          [France, Nanterre]\n",
       "Gevee                            [France, Nanterre]\n",
       "Innojam                    [Netherlands, Amsterdam]\n",
       "Kanoodle                           [Japan, Niihama]\n",
       "Lajo                               [Greece, Athens]\n",
       "Ntags                            [Portugal, Lisbon]\n",
       "Realpoint                        [Portugal, Lisbon]\n",
       "Rhycero                          [France, Nanterre]\n",
       "Riffpath                           [Greece, Athens]\n",
       "Roodel                          [Portugal, Aranhas]\n",
       "Shufflebeat                       [Portugal, Porto]\n",
       "Tagtune                       [Switzerland, Zürich]\n",
       "Teklist                       [Netherlands, Arnhem]\n",
       "Thoughtmix                      [Portugal, Amadora]\n",
       "Twitterbeat                      [France, Nanterre]\n",
       "Voomm                            [France, Nanterre]\n",
       "Wordify                   [United States, New York]\n",
       "Yozio                              [Greece, Athens]\n",
       "Zoonder                     [United States, Boston]\n",
       "Zooxo                      [United Kingdom, London]\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = (df.groupby(['company'])['country', 'city']\n",
    "       .apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SUCCES!*** Now there are no more NaN values.\n",
    "\n",
    "#### Clean the 'price' column by removing rows without a price and make sure all currencies are in euro.\n",
    "\n",
    "***I:*** We find all the unique entries in the price column that are not a price in euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['£', '$', '¥', '£-', '¥-', '$-', '-', 'void', 'nan', 'na']\n"
     ]
    }
   ],
   "source": [
    "listunique = []\n",
    "for i in range(0,len(df)):\n",
    "    price = str(df.iloc[i,3])\n",
    "    if '€' not in price:\n",
    "        regex1 = re.search(r'^(\\D+)[-]?\\d*[.]*\\d*', price)\n",
    "        regex2 = re.search(r'[-]?\\d*[.]*\\d*(\\D+)$', price)\n",
    "        if regex1 is not None:\n",
    "            group1 = regex1.group(1)\n",
    "            listunique.append(group1)\n",
    "        elif regex2 is not None:\n",
    "            group2 = regex2.group(1)\n",
    "            listunique.append(group2)\n",
    "\n",
    "onlylistunique = []\n",
    "for elem in listunique:\n",
    "    if elem not in onlylistunique:\n",
    "        onlylistunique.append(elem)   \n",
    "print(onlylistunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***II:*** We change the currency to euro in lines with '£', '$' and '¥' and for all the prices the currency symbol is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>187.99</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company country       city   price                date\n",
       "0  Chatterbridge   Spain  Barcelona  784.79 2016-01-02 00:01:05\n",
       "1           Lajo  Greece     Athens  187.99 2016-01-02 00:05:26\n",
       "2      Flipstorm  Greece     Athens  221.73 2016-01-02 00:18:30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(df)):  \n",
    "    price = str(df.iloc[i,3])\n",
    "    if '€' not in price:\n",
    "        if '£' in price:\n",
    "            pricepound = float(df.iloc[i,3][1:]) * 1.12305\n",
    "            df.iloc[i,3] = round(pricepound,2)\n",
    "        elif '$' in price:\n",
    "            pricedollar = float(df.iloc[i,3][1:]) * 0.912104 \n",
    "            df.iloc[i,3] = round(pricedollar,2)\n",
    "        elif '¥' in price:\n",
    "            priceyen = float(df.iloc[i,3][1:]) * 0.00851916\n",
    "            df.iloc[i,3] = round(priceyen,2)\n",
    "    else: \n",
    "        priceeuro = float(df.iloc[i,3][:-1])\n",
    "        df.iloc[i,3] = round(priceeuro,2)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websites used for currency:\n",
    "\n",
    "- Currency for £ to €: https://www.xe.com/currencyconverter/convert/?Amount=1&From=GBP&To=EUR visited: 3/10\n",
    "- Currency for $ to €: https://www.xe.com/currencyconverter/convert/?Amount=1&From=USD&To=EUR visited: 3/10\n",
    "- Currency for ¥ to €: https://www.xe.com/currencyconverter/convert/?Amount=1&From=JPY&To=EUR visited: 3/10\n",
    "\n",
    "***III***: We delete the lines with 'void', 'na', 'nan' and '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_price = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['price'] == 'void' or row['price'] == 'na' or row['price'] == 'nan' or row['price'] == '-' or pd.isna(row['price']) == True:\n",
    "        remove_price.append(index)  \n",
    "        \n",
    "df.drop(remove_price, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IV***: The data in the 'price' column is changed to float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company            object\n",
       "country            object\n",
       "city               object\n",
       "price             float64\n",
       "date       datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'] = pd.to_numeric(df['price'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SUCCESS!*** The currencies have been changed to euro and the data type is now float. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Status.\n",
    "\n",
    "The data has been cleaned and is now ready for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_rows = len(df)\n",
    "start_rows - end_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, 13 rows have been removed from the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task for a data scientists is to combine or enrich data from internal sources with data available from external sources. The purpose of this can be either to fix issues with the data or to make it easier to derive insights from the data.\n",
    "\n",
    "In this part you should enrich your data with data from at least one external source. You may look to part 4 for some  inspiration as to what is required. Your solution should be automated, i.e., you can not ask the reader of your notebook to download any data manually. You should argue why and what you expect to achieve by the enrichments you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enrich our data set we have contructed a new CSV file with more columns of data. \n",
    "\n",
    "This data has been derived from The World Bank. \n",
    "\n",
    "## MANGLER MERE INFO: ARGUE, where is the data from etc.\n",
    "\n",
    "## QUESTION: you can not ask the reader of your notebook to download any data manually.???? ER DET FORKERT DET VI HAR GJORT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://api.worldbank.org/v2/sources/2/country/GBR;USA;FRA;DEU;GRC;JPN;NLD;PRT;CHE;ESP/series/NY.GDP.PCAP.CD;SI.POV.GINI/data?format=json&mrnev=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = json_response['source']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_country = []\n",
    "list_value_GDP_dollar = []\n",
    "list_value_gini = []\n",
    "\n",
    "counter = 0\n",
    "for r in res:\n",
    "    inner_res = r.get('variable')\n",
    "    value = r.get('value')\n",
    "    counter += 1 \n",
    "    if counter == 2:\n",
    "        list_value_gini.append(value)\n",
    "        counter -= 2\n",
    "    else:\n",
    "        list_value_GDP_dollar.append(value)\n",
    "    for r in inner_res:\n",
    "        country = r.get('value')\n",
    "        list_country.append(country)\n",
    "        break\n",
    "\n",
    "unique_country = []\n",
    "for country in list_country:\n",
    "    if country not in unique_country:\n",
    "        unique_country.append(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_value_GDP_euro = []\n",
    "for i in list_value_GDP_dollar:\n",
    "    list_value_GDP_euro.append(i*0.912104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(list(zip(unique_country,list_value_GDP_euro,list_value_gini)), columns =['country','gdp_euro','gini_index']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>gdp_euro</th>\n",
       "      <th>gini_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>38756.543467</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>57135.119953</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country      gdp_euro  gini_index\n",
       "0  United Kingdom  38756.543467        33.2\n",
       "1   United States  57135.119953        41.5\n",
       "2          France  37819.155568        32.7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, new_df, on='country', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>gdp_euro</th>\n",
       "      <th>gini_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>412.55</td>\n",
       "      <td>2016-01-02 04:51:55</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>359.52</td>\n",
       "      <td>2016-01-02 07:20:59</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company country       city   price                date      gdp_euro  \\\n",
       "0  Chatterbridge   Spain  Barcelona  784.79 2016-01-02 00:01:05  27840.934107   \n",
       "1  Chatterbridge   Spain  Barcelona  412.55 2016-01-02 04:51:55  27840.934107   \n",
       "2  Chatterbridge   Spain  Barcelona  359.52 2016-01-02 07:20:59  27840.934107   \n",
       "\n",
       "   gini_index  \n",
       "0        36.2  \n",
       "1        36.2  \n",
       "2        36.2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company               object\n",
       "country               object\n",
       "city                  object\n",
       "price                float64\n",
       "date          datetime64[ns]\n",
       "gdp_euro             float64\n",
       "gini_index           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('transactions.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(\"transactions\", conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1200c0ce0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('SELECT date(date) FROM transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20555"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>gdp_euro</th>\n",
       "      <th>gini_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8813</th>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>-675.81</td>\n",
       "      <td>2016-06-28 06:31:55</td>\n",
       "      <td>38756.543467</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>-521.70</td>\n",
       "      <td>2017-09-09 04:05:49</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>-364.17</td>\n",
       "      <td>2018-01-27 14:43:38</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>-297.24</td>\n",
       "      <td>2016-09-22 18:01:17</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9811</th>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>-277.67</td>\n",
       "      <td>2018-04-18 03:51:50</td>\n",
       "      <td>38756.543467</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>-217.88</td>\n",
       "      <td>2016-01-05 12:21:25</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>Yozio</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>-185.05</td>\n",
       "      <td>2016-11-07 08:16:26</td>\n",
       "      <td>18537.832973</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>-181.47</td>\n",
       "      <td>2016-01-25 09:38:31</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12466</th>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>-173.53</td>\n",
       "      <td>2016-10-23 14:27:46</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>-168.28</td>\n",
       "      <td>2017-01-02 12:09:55</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16345</th>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>-158.51</td>\n",
       "      <td>2018-03-22 02:38:12</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17701</th>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>-158.36</td>\n",
       "      <td>2018-09-23 21:50:08</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>-158.02</td>\n",
       "      <td>2016-01-15 15:31:31</td>\n",
       "      <td>18537.832973</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16154</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>-156.42</td>\n",
       "      <td>2018-02-25 18:09:20</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>-148.34</td>\n",
       "      <td>2016-02-08 20:41:09</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17306</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>-141.76</td>\n",
       "      <td>2018-07-27 03:20:28</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>Wordify</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York</td>\n",
       "      <td>-140.38</td>\n",
       "      <td>2018-12-12 22:41:50</td>\n",
       "      <td>57135.119953</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>Yozio</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>-133.25</td>\n",
       "      <td>2016-01-22 14:23:10</td>\n",
       "      <td>18537.832973</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8169</th>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>-130.95</td>\n",
       "      <td>2018-02-20 10:02:16</td>\n",
       "      <td>43959.381213</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20381</th>\n",
       "      <td>Bubblemix</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Asaka</td>\n",
       "      <td>-123.10</td>\n",
       "      <td>2016-05-29 16:23:37</td>\n",
       "      <td>35833.590556</td>\n",
       "      <td>32.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17618</th>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>-121.28</td>\n",
       "      <td>2018-09-11 14:32:24</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>Eimbee</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>-119.86</td>\n",
       "      <td>2016-06-13 21:20:51</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>Rhycero</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>-119.83</td>\n",
       "      <td>2018-05-28 21:13:30</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18122</th>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>-109.47</td>\n",
       "      <td>2018-11-17 12:11:04</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20505</th>\n",
       "      <td>Kanoodle</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Niihama</td>\n",
       "      <td>-106.93</td>\n",
       "      <td>2018-05-09 03:07:40</td>\n",
       "      <td>35833.590556</td>\n",
       "      <td>32.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>-106.89</td>\n",
       "      <td>2016-05-08 20:17:07</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8726</th>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>-102.53</td>\n",
       "      <td>2016-04-30 18:55:46</td>\n",
       "      <td>38756.543467</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>-95.08</td>\n",
       "      <td>2016-01-07 08:45:08</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8482</th>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>-92.97</td>\n",
       "      <td>2018-11-12 00:00:18</td>\n",
       "      <td>43959.381213</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>Rhycero</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>-91.78</td>\n",
       "      <td>2016-10-04 22:32:11</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19240</th>\n",
       "      <td>Wordify</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York</td>\n",
       "      <td>1734.60</td>\n",
       "      <td>2017-08-19 02:07:40</td>\n",
       "      <td>57135.119953</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15617</th>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>1735.89</td>\n",
       "      <td>2017-12-18 08:02:38</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>1737.81</td>\n",
       "      <td>2018-01-27 02:33:47</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1743.18</td>\n",
       "      <td>2018-07-10 19:39:37</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>Eimbee</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>1756.72</td>\n",
       "      <td>2017-09-14 05:39:47</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12729</th>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>1772.29</td>\n",
       "      <td>2016-11-27 01:19:21</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>1773.72</td>\n",
       "      <td>2017-09-22 21:02:53</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19146</th>\n",
       "      <td>Zoonder</td>\n",
       "      <td>United States</td>\n",
       "      <td>Boston</td>\n",
       "      <td>1778.84</td>\n",
       "      <td>2017-06-07 21:07:45</td>\n",
       "      <td>57135.119953</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>1791.75</td>\n",
       "      <td>2016-08-06 08:11:35</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1795.82</td>\n",
       "      <td>2017-04-28 21:39:26</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15701</th>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>1797.42</td>\n",
       "      <td>2017-12-29 08:14:04</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>Avaveo</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>1799.59</td>\n",
       "      <td>2018-09-19 20:20:36</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1800.82</td>\n",
       "      <td>2016-05-26 18:53:24</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13026</th>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>1802.74</td>\n",
       "      <td>2017-01-06 01:59:44</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>1812.14</td>\n",
       "      <td>2017-10-28 20:56:05</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1813.74</td>\n",
       "      <td>2017-04-15 19:26:09</td>\n",
       "      <td>27840.934107</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15640</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>1839.54</td>\n",
       "      <td>2017-12-21 10:30:18</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17425</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>1853.15</td>\n",
       "      <td>2018-08-14 23:14:18</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>1861.57</td>\n",
       "      <td>2018-10-08 00:32:01</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13551</th>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>1869.63</td>\n",
       "      <td>2017-03-19 15:05:58</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>Roodel</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Aranhas</td>\n",
       "      <td>1895.58</td>\n",
       "      <td>2016-11-04 01:23:52</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>1901.39</td>\n",
       "      <td>2016-07-28 20:36:53</td>\n",
       "      <td>18537.832973</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>1912.36</td>\n",
       "      <td>2016-12-21 13:36:34</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>Eimbee</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>1958.86</td>\n",
       "      <td>2017-06-09 07:28:03</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>Roodel</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Aranhas</td>\n",
       "      <td>1975.46</td>\n",
       "      <td>2016-09-08 05:17:17</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>2035.70</td>\n",
       "      <td>2018-11-26 02:42:16</td>\n",
       "      <td>37819.155568</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>2092.49</td>\n",
       "      <td>2016-09-07 13:31:12</td>\n",
       "      <td>18537.832973</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11754</th>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>2126.82</td>\n",
       "      <td>2016-07-29 01:30:35</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>2140.64</td>\n",
       "      <td>2016-09-09 04:47:05</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16463</th>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>2174.74</td>\n",
       "      <td>2018-04-06 06:10:25</td>\n",
       "      <td>21111.317437</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20555 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             company         country        city    price                date  \\\n",
       "8813           Zooxo  United Kingdom      London  -675.81 2016-06-28 06:31:55   \n",
       "901    Chatterbridge           Spain   Barcelona  -521.70 2017-09-09 04:05:49   \n",
       "15936          Ntags        Portugal      Lisbon  -364.17 2018-01-27 14:43:38   \n",
       "12217     Thoughtmix        Portugal     Amadora  -297.24 2016-09-22 18:01:17   \n",
       "9811           Zooxo  United Kingdom      London  -277.67 2018-04-18 03:51:50   \n",
       "3441       Flipstorm          France    Nanterre  -217.88 2016-01-05 12:21:25   \n",
       "2548           Yozio          Greece      Athens  -185.05 2016-11-07 08:16:26   \n",
       "38     Chatterbridge           Spain   Barcelona  -181.47 2016-01-25 09:38:31   \n",
       "12466          Ntags        Portugal      Lisbon  -173.53 2016-10-23 14:27:46   \n",
       "12997    Shufflebeat        Portugal       Porto  -168.28 2017-01-02 12:09:55   \n",
       "16345    Brainsphere        Portugal       Braga  -158.51 2018-03-22 02:38:12   \n",
       "17701    Shufflebeat        Portugal       Porto  -158.36 2018-09-23 21:50:08   \n",
       "1656       Flipstorm          Greece      Athens  -158.02 2016-01-15 15:31:31   \n",
       "16154     Thoughtmix        Portugal     Amadora  -156.42 2018-02-25 18:09:20   \n",
       "10491     Thoughtmix        Portugal     Amadora  -148.34 2016-02-08 20:41:09   \n",
       "17306     Thoughtmix        Portugal     Amadora  -141.76 2018-07-27 03:20:28   \n",
       "19867        Wordify   United States    New York  -140.38 2018-12-12 22:41:50   \n",
       "1678           Yozio          Greece      Athens  -133.25 2016-01-22 14:23:10   \n",
       "8169        Buzzbean         Germany  Düsseldorf  -130.95 2018-02-20 10:02:16   \n",
       "20381      Bubblemix           Japan       Asaka  -123.10 2016-05-29 16:23:37   \n",
       "17618    Brainsphere        Portugal       Braga  -121.28 2018-09-11 14:32:24   \n",
       "4213          Eimbee          France    Nanterre  -119.86 2016-06-13 21:20:51   \n",
       "6609         Rhycero          France    Nanterre  -119.83 2018-05-28 21:13:30   \n",
       "18122    Shufflebeat        Portugal       Porto  -109.47 2018-11-17 12:11:04   \n",
       "20505       Kanoodle           Japan     Niihama  -106.93 2018-05-09 03:07:40   \n",
       "4064     Twitterbeat          France    Nanterre  -106.89 2016-05-08 20:17:07   \n",
       "8726           Zooxo  United Kingdom      London  -102.53 2016-04-30 18:55:46   \n",
       "10260     Thoughtmix        Portugal     Amadora   -95.08 2016-01-07 08:45:08   \n",
       "8482        Buzzbean         Germany  Düsseldorf   -92.97 2018-11-12 00:00:18   \n",
       "4686         Rhycero          France    Nanterre   -91.78 2016-10-04 22:32:11   \n",
       "...              ...             ...         ...      ...                 ...   \n",
       "19240        Wordify   United States    New York  1734.60 2017-08-19 02:07:40   \n",
       "15617    Brainsphere        Portugal       Braga  1735.89 2017-12-18 08:02:38   \n",
       "15931    Shufflebeat        Portugal       Porto  1737.81 2018-01-27 02:33:47   \n",
       "1328   Chatterbridge           Spain   Barcelona  1743.18 2018-07-10 19:39:37   \n",
       "5853          Eimbee          France    Nanterre  1756.72 2017-09-14 05:39:47   \n",
       "12729    Brainsphere        Portugal       Braga  1772.29 2016-11-27 01:19:21   \n",
       "14968     Thoughtmix        Portugal     Amadora  1773.72 2017-09-22 21:02:53   \n",
       "19146        Zoonder   United States      Boston  1778.84 2017-06-07 21:07:45   \n",
       "11817    Shufflebeat        Portugal       Porto  1791.75 2016-08-06 08:11:35   \n",
       "703    Chatterbridge           Spain   Barcelona  1795.82 2017-04-28 21:39:26   \n",
       "15701    Brainsphere        Portugal       Braga  1797.42 2017-12-29 08:14:04   \n",
       "6969          Avaveo          France    Nanterre  1799.59 2018-09-19 20:20:36   \n",
       "229    Chatterbridge           Spain   Barcelona  1800.82 2016-05-26 18:53:24   \n",
       "13026          Ntags        Portugal      Lisbon  1802.74 2017-01-06 01:59:44   \n",
       "5991     Twitterbeat          France    Nanterre  1812.14 2017-10-28 20:56:05   \n",
       "682    Chatterbridge           Spain   Barcelona  1813.74 2017-04-15 19:26:09   \n",
       "15640     Thoughtmix        Portugal     Amadora  1839.54 2017-12-21 10:30:18   \n",
       "17425     Thoughtmix        Portugal     Amadora  1853.15 2018-08-14 23:14:18   \n",
       "7032     Twitterbeat          France    Nanterre  1861.57 2018-10-08 00:32:01   \n",
       "13551          Ntags        Portugal      Lisbon  1869.63 2017-03-19 15:05:58   \n",
       "12545         Roodel        Portugal     Aranhas  1895.58 2016-11-04 01:23:52   \n",
       "2349       Flipstorm          Greece      Athens  1901.39 2016-07-28 20:36:53   \n",
       "4973     Twitterbeat          France    Nanterre  1912.36 2016-12-21 13:36:34   \n",
       "5534          Eimbee          France    Nanterre  1958.86 2017-06-09 07:28:03   \n",
       "12082         Roodel        Portugal     Aranhas  1975.46 2016-09-08 05:17:17   \n",
       "7196     Twitterbeat          France    Nanterre  2035.70 2018-11-26 02:42:16   \n",
       "2438       Flipstorm          Greece      Athens  2092.49 2016-09-07 13:31:12   \n",
       "11754          Ntags        Portugal      Lisbon  2126.82 2016-07-29 01:30:35   \n",
       "12098          Ntags        Portugal      Lisbon  2140.64 2016-09-09 04:47:05   \n",
       "16463     Thoughtmix        Portugal     Amadora  2174.74 2018-04-06 06:10:25   \n",
       "\n",
       "           gdp_euro  gini_index  \n",
       "8813   38756.543467        33.2  \n",
       "901    27840.934107        36.2  \n",
       "15936  21111.317437        35.5  \n",
       "12217  21111.317437        35.5  \n",
       "9811   38756.543467        33.2  \n",
       "3441   37819.155568        32.7  \n",
       "2548   18537.832973        36.0  \n",
       "38     27840.934107        36.2  \n",
       "12466  21111.317437        35.5  \n",
       "12997  21111.317437        35.5  \n",
       "16345  21111.317437        35.5  \n",
       "17701  21111.317437        35.5  \n",
       "1656   18537.832973        36.0  \n",
       "16154  21111.317437        35.5  \n",
       "10491  21111.317437        35.5  \n",
       "17306  21111.317437        35.5  \n",
       "19867  57135.119953        41.5  \n",
       "1678   18537.832973        36.0  \n",
       "8169   43959.381213        31.7  \n",
       "20381  35833.590556        32.1  \n",
       "17618  21111.317437        35.5  \n",
       "4213   37819.155568        32.7  \n",
       "6609   37819.155568        32.7  \n",
       "18122  21111.317437        35.5  \n",
       "20505  35833.590556        32.1  \n",
       "4064   37819.155568        32.7  \n",
       "8726   38756.543467        33.2  \n",
       "10260  21111.317437        35.5  \n",
       "8482   43959.381213        31.7  \n",
       "4686   37819.155568        32.7  \n",
       "...             ...         ...  \n",
       "19240  57135.119953        41.5  \n",
       "15617  21111.317437        35.5  \n",
       "15931  21111.317437        35.5  \n",
       "1328   27840.934107        36.2  \n",
       "5853   37819.155568        32.7  \n",
       "12729  21111.317437        35.5  \n",
       "14968  21111.317437        35.5  \n",
       "19146  57135.119953        41.5  \n",
       "11817  21111.317437        35.5  \n",
       "703    27840.934107        36.2  \n",
       "15701  21111.317437        35.5  \n",
       "6969   37819.155568        32.7  \n",
       "229    27840.934107        36.2  \n",
       "13026  21111.317437        35.5  \n",
       "5991   37819.155568        32.7  \n",
       "682    27840.934107        36.2  \n",
       "15640  21111.317437        35.5  \n",
       "17425  21111.317437        35.5  \n",
       "7032   37819.155568        32.7  \n",
       "13551  21111.317437        35.5  \n",
       "12545  21111.317437        35.5  \n",
       "2349   18537.832973        36.0  \n",
       "4973   37819.155568        32.7  \n",
       "5534   37819.155568        32.7  \n",
       "12082  21111.317437        35.5  \n",
       "7196   37819.155568        32.7  \n",
       "2438   18537.832973        36.0  \n",
       "11754  21111.317437        35.5  \n",
       "12098  21111.317437        35.5  \n",
       "16463  21111.317437        35.5  \n",
       "\n",
       "[20555 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_by_price = df.sort_values('price')\n",
    "sort_by_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
